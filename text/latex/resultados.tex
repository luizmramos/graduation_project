\externaldocument{metodologia}
\externaldocument{fundamentacao_teorica}
\externaldocument{proposta_de_classificador}
\externaldocument{problema}

\section{Base de dados}
A base de dados para a classificação de postagens foi adquirida a partir da extensão do Chrome descrita na Seção \ref{sec:plugin_chrome}. A classificação foi feita manualmente por diversos supervisores, classificando cada postagem nas diferentes categorias explicitadas na Seção \ref{ref:classes_adotadas}. 

O gráfico da Figura \ref{fig:classes_freq} ilustra a proporção entre as diferentes classes na base de dados obtida.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.9\textwidth]{classes_freq.png}
	\caption{Histograma representativo da base de dados de postagens adquirida}
	\label{fig:classes_freq}
\end{figure}

A menor base é de `Notícias', com apenas 16 postagens, e a maior é `Política / Economia' com 172 postagens. O total de postagens é 757. Observa-se que este não é um número muito grande para uma base de dados, ainda mais com um total de 14 classes, mas foi o que foi possível de se adquirir.

\section{Naïve Bayes utilizando apenas o texto}

Nesta primeira abordagem, o classificador obteve uma acurácia média (ao longo de 100 partições aleatórias diferentes da base de dados em treinamento e validação, conforme o explicado na Seção \ref{sec:validacao}) de 49.7\%, ou seja, o classificador acerta basicamente 1 a cada 2 postagens. Como já foi dito na Seção \ref{sec:acuracia}, a acurácia é uma métrica bem ruim para avaliar um classifiador. Desta forma, foram consideradas as outras estatísticas explicadas no capítulo de metodologia, para uma análise mais profunda.

A acurácia esperada para este classificador, utilizando a Equação \ref{eq:acuracia_esperada}, é de 14.16\%. O $Kappa$ neste caso foi de 41.4\%. Segundo o benchmark de Landis e Koch \cite{landis1977measurement}, trata-se de um resultado moderado. Note que a estatística $Kappa$ agrega muito mais informação que uma simples acurácia.

É interessante observar como o Kappa e a acurácia variam conforme se aumenta o tamanho da base de dado. Para tal, repetiu-se o processo de treinamento e validação com a base de dados de tamanho variável (pegando-se subconjuntos aleatórios da base de dados original). Manteve-se sempre uma proporção de 75\% pra treinamento e 25\% para validação. A Figura \ref{fig:nb_apenas_com_texto_accuracy_graph} mostra o crescimento da acurácia, enquanto que a Figura \ref{fig:nb_apenas_com_texto_kappa_graph} mostra o crescimento do Kappa.

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_apenas_com_texto_accuracy_graph.png}
	\caption{Acurácia em função da quantidade de postagens na base de dados (treinamento + validação) para NB simples}
	\label{fig:nb_apenas_com_texto_accuracy_graph}
\end{figure}

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_apenas_com_texto_kappa_graph.png}
	\caption{Kappa em função da quantidade de postagens na base de dados (treinamento + validação) para NB simples}
	\label{fig:nb_apenas_com_texto_kappa_graph}
\end{figure}


Como pode ser observado nas figuras \ref{fig:nb_apenas_com_texto_accuracy_graph} e \ref{fig:nb_apenas_com_texto_kappa_graph}, quanto maior a base de dados, melhor o classificador fica. Alem disso, como este crescimento ainda não se estabilizou, fica claro que se a base de dados fosse substancialmente maior (dezenas de milhares de postagens), os resultados seriam muito melhores.

Entretanto, não é viável, para os propósitos deste trabalho, acumular tantos dados. Portanto trabalhou-se com essa quantidade reduzida de postagens, tentando-se introduzir melhoras qualitativas ao classificador com as modificações descritas na Seção \ref{sec:proposta_de_classificador}.

Para se compreender onde exatamente o classificador está ruim, rodou-se novamente o programa com apenas uma iteração e construiu-se a matriz de confusão para os resultados obtidos, como pode ser visto na Tabela \ref{tab:nb_apenas_com_o_texto}.

Para este exemplo teve-se:

$acuracia=0.529101$

$acuracia\_esperada=0.138154$

$Kappa=0.453615$


A Tabela \ref{tab:nb_apenas_com_o_texto} apresenta a matriz de confusão obtida. A Figura \ref{fig:nb_apenas_com_o_texto} consiste numa representação gráfica da matriz, para facilitar a sua visualização. Nesta representação, quanto mais vermelha a célula, mais próximo seu valor está do 0. O amarelo representa valores maiores ou iguais a 7. Números intermediários possuem cores intermediárias.


\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c  c  c  c  c  c  c  c  c  c  c }
			\hline
			Beb & Cel & Cie & Edu & Esp & Fil & Hum & Min & Not & Pes & Pol & Pro & Sau & Tur\\
			\hline
			7 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 2 & 0 & 0\\
			0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 1 & 2 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
			0 & 0 & 2 & 8 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 1 & 0\\
			0 & 0 & 0 & 1 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
			0 & 0 & 1 & 0 & 0 & 4 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\
			0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 1 & 1 & 1 & 0 & 1 & 1 & 9 & 1 & 3 & 2 & 1 & 0 & 1\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			3 & 3 & 0 & 1 & 2 & 0 & 0 & 1 & 0 & 21 & 0 & 3 & 0 & 1\\
			1 & 1 & 4 & 2 & 2 & 1 & 7 & 4 & 3 & 1 & 38 & 2 & 4 & 1\\
			0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 2 & 1 & 2\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Matriz de confusao para a NB apenas com o texto}
	\label{tab:nb_apenas_com_o_texto}
\end{table}

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_apenas_com_o_texto.png}
	\caption{Heatmap da matriz de confusão da Tabela \ref{tab:nb_apenas_com_o_texto}}
	\label{fig:nb_apenas_com_o_texto}
\end{figure}

O Heatmap da Figura \ref{fig:nb_apenas_com_o_texto} e a Tabela \ref{tab:nb_apenas_com_o_texto} deixam claros vários problemas do classificador. Por exemplo, a linha de política está muito amarela como um todo. Isso mostra que o classificador está com alta tendência de escolher política como assunto, mesmo quando isso não está certo. Isto ocorre porque há muito mais postagens de política do que de outros assuntos, então é mais provável que uma nova postagem seja de política. Isso acaba gerando uma alta abrangência, porém baixa precisão para a este assunto, como pode ser visto na tabela \ref{tab:nb_apenas_com_o_texto_prec_rec}.

Outras estatísticas analisadas são as precisões, as abrangências e os f1scores para cada uma das classes, conforme relacionado na Tabela \ref{tab:nb_apenas_com_o_texto_prec_rec}.

\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c }
			\hline
			Classe & Precisao & Abrangencia & F1score \\
			\hline
			Bebes & 0.636364 & 0.636364 & 0.636364 \\
			Celebridade & 0.500000 & 0.125000 & 0.200000 \\
			Ciencia & 0.400000 & 0.153846 & 0.222222 \\
			Educacao & 0.571429 & 0.615385 & 0.592593 \\
			Esporte & 0.714286 & 0.555556 & 0.625000 \\
			Filmes & 0.571429 & 0.500000 & 0.533333 \\
			Humor & 0.500000 & 0.083333 & 0.142857 \\
			Minorias & 0.409091 & 0.642857 & 0.500000 \\
			Noticias & 1.000000 & 0.000000 & 1.000000 \\
			Pessoal & 0.600000 & 0.777778 & 0.677419 \\
			Politica & 0.535211 & 0.883721 & 0.666667 \\
			Propaganda & 0.000000 & 1.000000 & 0.000000 \\
			Saude & 0.142857 & 0.166667 & 0.153846 \\
			Turismo & 1.000000 & 0.333333 & 0.500000 \\
			Media Micro & 0.529101 & 0.529101 & 0.529101 \\
			Media Macro & 0.541476 & 0.462417 & 0.498833 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Precisão e abrangencia para NB apenas com o texto}
	\label{tab:nb_apenas_com_o_texto_prec_rec}
\end{table}

Como pode ser visto na tabela \ref{tab:nb_apenas_com_o_texto_prec_rec}, os resultados das precisões e abrangências estão muito ruins. Isso é reiterado pelo Heatmap da Figura \ref{fig:nb_apenas_com_o_texto}. As classificações ainda estão muito espalhadas.


\section{Naïve Bayes com Features Adicionais}
% Isso piora o classificador pois adiciona redundancia (e quebra a nocao de independencia condicional)

% citar a secao que explica essas features

A acurácia média obtida depois da adição das features extras foi de 51.1\%. A métrica Kappa foi de 42.5\%. Observa-se portanto que houve uma pequena melhora em relação as redes Bayesianas com o texto puro(o Kappa variou de 41.4\% para 42.5\%). 

O motivo da melhoria ser tão pequena é que ocorrem dois efeitos opostos quando se incluem essas novas features. Por um lado, essas features adicionam novas informações que possibilitam que haja uma melhor classificação. Por outro lado, elas são muitas vezes dependentes condicionalmente das palavras do texto (e entre si). Como as NB assumem independência condicional, a adição de features dependentes pode piorar a rede. O resultado da soma desses dois efeitos foi ligeiramente positivo neste caso.

A Figura \ref{fig:nb_features_extras_accuracy_graph} abaixo mostra a evolução da acurácia das NB com features extras em função do tamanho da base de dados. A Figura \ref{fig:nb_features_extras_kappa_graph} mostra a relação do Kappa com o tamanho da base de dados. A Figura \ref{fig:nb_features_extras_vs_apenas_texto_kappa_graph} compara os gráficos do Kappa para as NB com e sem features extras.

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_features_extras_accuracy_graph.png}
	\caption{Acurácia em função da quantidade de postagens na base de dados (treinamento + validação) para NB com features extras (alem das palavras do texto)}
	\label{fig:nb_features_extras_accuracy_graph}
\end{figure}


\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_features_extras_kappa_graph.png}
	\caption{Kappa em função da quantidade de postagens na base de dados (treinamento + validação) para NB com features extras (alem das palavras do texto)}
	\label{fig:nb_features_extras_kappa_graph}
\end{figure}

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_features_extras_vs_apenas_texto_kappa_graph.png}
	\caption{Sobreposição dos gráficos do Kappa em função da quantidade de postagens na base de dados para NB com e sem as features extras}
	\label{fig:nb_features_extras_vs_apenas_texto_kappa_graph}
\end{figure}

O programa foi executado novamente, desta vez com apenas uma única iteração para se analisa a matriz de confusão gerada. Para este exemplo teve-se:

$acuracia=0.513228$

$acuracia\_esperada=0.140058$

$Kappa=0.433948$


A Tabela \ref{tab:nb_com_features_adicionais} apresenta a matriz de confusão obtida.


\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c  c  c  c  c  c  c  c  c  c  c }
			\hline
			Beb & Cel & Cie & Edu & Esp & Fil & Hum & Min & Not & Pes & Pol & Pro & Sau & Tur\\
			\hline
			6 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 1 & 3 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 1 & 0\\
			0 & 0 & 3 & 3 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
			0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 0 & 0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 0 & 0 & 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			1 & 0 & 0 & 2 & 1 & 1 & 0 & 6 & 2 & 1 & 1 & 0 & 1 & 0\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			4 & 3 & 0 & 3 & 6 & 3 & 4 & 2 & 1 & 22 & 1 & 1 & 1 & 2\\
			0 & 2 & 2 & 4 & 1 & 2 & 2 & 5 & 5 & 2 & 39 & 0 & 7 & 0\\
			0 & 0 & 1 & 0 & 1 & 3 & 0 & 0 & 0 & 0 & 0 & 3 & 0 & 1\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 2 & 0\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 4\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Matriz de confusao para a NB com features adicionais}
	\label{tab:nb_com_features_adicionais}
\end{table}


A Figura \ref{fig:nb_com_features_adicionais} consiste numa representação gráfica da matriz de confusão. Como pode ser observado neste Heatmap, os resultados ainda são bem ruins, com uma quantidade significativa de erros e alta tendência do classificador de escolher as classes Política ou Pessoal (as duas classes com maior quantidade de postagens na base de dados).

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_com_features_adicionais.png}
	\caption{Heatmap da matriz de confusão da Tabela \ref{tab:nb_com_features_adicionais}}
	\label{fig:nb_com_features_adicionais}
\end{figure}

Outras estatísticas analisadas são as precisões, as abrangências e os f1scores para cada uma das classes, conforme relacionado na Tabela \ref{tab:nb_com_features_adicionais_prec_rec}. Estas estatísticas também estão bem ruins. Na maior parte das classes nem a abrangência nem a precisão foram boas. As classes mais comuns (como Política e Pessoal) tiveram boa abrangência, porém baixa precisão.

\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c }
			\hline
			Classe & Precisao & Abrangencia & F1score \\
			\hline
			Bebes & 0.750000 & 0.545455 & 0.631579 \\
			Celebridade & 1.000000 & 0.000000 & 0.000000 \\
			Ciencia & 0.375000 & 0.333333 & 0.352941 \\
			Educacao & 0.375000 & 0.250000 & 0.300000 \\
			Esporte & 1.000000 & 0.090909 & 0.166667 \\
			Filmes & 1.000000 & 0.230769 & 0.375000 \\
			Humor & 1.000000 & 0.416667 & 0.588235 \\
			Minorias & 0.375000 & 0.461538 & 0.413793 \\
			Noticias & 1.000000 & 0.000000 & 0.000000 \\
			Pessoal & 0.415094 & 0.880000 & 0.564103 \\
			Politica & 0.549296 & 0.928571 & 0.690265 \\
			Propaganda & 0.333333 & 0.500000 & 0.400000 \\
			Saude & 0.666667 & 0.166667 & 0.266667 \\
			Turismo & 1.000000 & 0.500000 & 0.666667 \\
			Media Micro & 0.513228 & 0.513228 & 0.513228 \\
			Media Macro & 0.702814 & 0.378850 & 0.492317 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Precisão e abrangencia para NB com features adicionais}
	\label{tab:nb_com_features_adicionais_prec_rec}
\end{table}


\section{Weighted Naïve Bayes utilizando apenas o texto}

A acurácia média obtida, depois da adição de pesos nas features e utilizando apenas as palavras do texto, foi de 53.5\%. A métrica Kappa foi de 48.2\%. 

Observa-se portanto que houve uma melhora considerável na métrica Kappa em relação às abordagens anteriores e uma melhora pequena na acurácia. A interpretação para isso é que o classificador está acertando mais de classes diversificadas. Enquanto nos casos anteriores, o classificador se limitava a escolher as classes mais frequentes e errar muito as menos frequentes, agora ele está acertando um pouco de cada classe. Isso faz com que o Kappa melhore mais do que a acurácia.

As Figuras \ref{fig:wnb_somente_texto_accuracy_graph} e \ref{fig:wnb_somente_texto_accuracy_graph} mostram, respectivamente, a evolução da acurácia e do Kappa em função do tamanho da base de dados. Ambos estão crescendo de forma semelhante, o que reitera a ideia de que quantidade de dados é muito importante independentemente do classificador usado. A Figura \ref{fig:nb_somente_texto_vs_wnb_kappa_graph} compara o Kappa do NB tradicional com o Kappa do Weighted NB pro caso de só se considerar o texto da postagem. Dá pra se observar a melhora obtida. Isso comprova o fato de que é ingênuo se assumir a independência condicional entre as palavras do texto. Ao se ponderar de forma diferente as palavras, aliviou-se essa hipótese, tornando o classificador melhor. 

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{wnb_somente_texto_accuracy_graph.png}
	\caption{Acurácia em função da quantidade de postagens na base de dados (treinamento + validação) para a Weighted NB utilizando apenas o texto}
	\label{fig:wnb_somente_texto_accuracy_graph}
\end{figure}


\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{wnb_somente_texto_kappa_graph.png}
	\caption{Kappa em função da quantidade de postagens na base de dados (treinamento + validação) para a Weighted NB utilizando apenas o texto}
	\label{fig:wnb_somente_texto_kappa_graph}
\end{figure}

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_somente_texto_vs_wnb_kappa_graph.png}
	\caption{Sobreposição dos gráficos do Kappa em função da quantidade de postagens na base de dados para o NB Simples e o Weighted NB}
	\label{fig:nb_somente_texto_vs_wnb_kappa_graph}
\end{figure}

Para analisar melhor os erros que este classificador está cometendo, rodou-se o mesmo novamente, gerando-se a matriz de confusão. Para este exemplo teve-se:

$acuracia=0.544974$

$acuracia\_esperada=0.104000$

$Kappa=0.492158$


A Tabela \ref{tab:weighted_nb_apenas_com_texto} apresenta a matriz de confusão obtida. A Figura \ref{fig:weighted_nb_apenas_com_texto} consiste numa representação gráfica da matriz de confusão.


\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c  c  c  c  c  c  c  c  c  c  c }
			\hline
			Beb & Cel & Cie & Edu & Esp & Fil & Hum & Min & Not & Pes & Pol & Pro & Sau & Tur\\
			\hline
			7 & 0 & 1 & 0 & 0 & 1 & 0 & 2 & 0 & 1 & 0 & 1 & 0 & 0\\
			0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 0 & 6 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 1 & 1\\
			1 & 0 & 3 & 8 & 1 & 0 & 0 & 1 & 0 & 0 & 2 & 1 & 2 & 0\\
			0 & 0 & 0 & 0 & 8 & 0 & 0 & 0 & 0 & 0 & 2 & 1 & 0 & 0\\
			0 & 1 & 0 & 0 & 0 & 12 & 0 & 0 & 0 & 1 & 2 & 1 & 0 & 2\\
			0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			2 & 1 & 1 & 1 & 0 & 0 & 2 & 9 & 1 & 4 & 12 & 0 & 0 & 2\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			1 & 0 & 0 & 0 & 2 & 0 & 1 & 1 & 0 & 12 & 0 & 0 & 0 & 1\\
			1 & 2 & 0 & 1 & 0 & 1 & 3 & 0 & 0 & 2 & 24 & 0 & 2 & 1\\
			0 & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 0 & 0 & 1 & 3 & 0 & 0\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 6 & 0\\
			0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 5\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Matriz de confusao para a Weighted NB apenas com texto}
	\label{tab:weighted_nb_apenas_com_texto}
\end{table}


\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{weighted_nb_apenas_com_texto.png}
	\caption{Heatmap da matriz de confusão da Tabela \ref{tab:weighted_nb_apenas_com_texto}}
	\label{fig:weighted_nb_apenas_com_texto}
\end{figure}


Como pode ser visto na Figura \ref{fig:weighted_nb_apenas_com_texto}, este novo classificador é qualitativamente melhor que os anteriores. O Heatmap possui muito menos células fora da diagonal principal com tonalidades fortes de amarelo. Ele tambem deixa claro o erro mais comum do classificador: considerar como Minorias várias postagens de Política. Este erro é de certa forma aceitável e justificável, podendo ser cometido até por um ser humano. Muitas das postagens de Minorias podem falar sobre medidas públicas a favor ou contra determinadas classes de pessoas, ou falar de partidos e deputados apoiadores (Jean Wyllys do PSOL, por exemplo) e criticar ou defender ideologias políticas. A verdade é que estas postagens deveriam ter sido classificadas com ambas as classes em um classificador \emph{multi-class / multi-label} como explicado na Seção \ref{sec:multi_label}.

Outras estatísticas analisadas são as precisões, as abrangências e os f1scores para cada uma das classes, conforme relacionado na Tabela \ref{tab:weighted_nb_apenas_com_texto_prec_rec}. Apesar de eles ainda estarem ruins, melhoraram em comparação com os classificadores anteriores.

\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c }
			\hline
			Classe & Precisao & Abrangencia & F1score \\
			\hline
			Bebes & 0.538462 & 0.583333 & 0.560000 \\
			Celebridade & 0.500000 & 0.200000 & 0.285714 \\
			Ciencia & 0.545455 & 0.545455 & 0.545455 \\
			Educacao & 0.421053 & 0.615385 & 0.500000 \\
			Esporte & 0.727273 & 0.615385 & 0.666667 \\
			Filmes & 0.631579 & 0.800000 & 0.705882 \\
			Humor & 1.000000 & 0.200000 & 0.333333 \\
			Minorias & 0.257143 & 0.642857 & 0.367347 \\
			Noticias & 1.000000 & 0.000000 & 0.000000 \\
			Pessoal & 0.666667 & 0.600000 & 0.631579 \\
			Politica & 0.648649 & 0.533333 & 0.585366 \\
			Propaganda & 0.375000 & 0.428571 & 0.400000 \\
			Saude & 1.000000 & 0.545455 & 0.705882 \\
			Turismo & 0.625000 & 0.416667 & 0.500000 \\
			Media Micro & 0.544974 & 0.544974 & 0.544974 \\
			Media Macro & 0.638306 & 0.480460 & 0.548248 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Precisão e abrangencia para Weighted NB apenas com texto}
	\label{tab:weighted_nb_apenas_com_texto_prec_rec}
\end{table}


\section{Weighted Naïve Bayes com Features Adicionais}
% Nesse caso nao tem problema adicionar features redundantes pois os pesos aliviam a hipotese de independencia condicional
Como será apresentado a seguir, adicionar as features extras no classificador com Weighted NB trás uma melhora considerável no resultado obtido. Isto ocorre pois as Weighted NB não fazem a consideração de independência e muitas dessas features extras são muito determinantes na classificação. Por exemplo, postagens Pessoais costumam ter pessoas e lugais marcados, certas páginas do Facebook costumam postar sempre sobre o mesmo assunto (partidos políticos postam de Política, páginas de produtos fazem propaganda, páginas de humor sempre postam humor, etc). Todas essas informações introduzidas pelas features extras são muito bem capturadas pelas Weighted NB.

A acurácia média obtida neste caso, depois da adição das features extras nas Weighted NB, foi de 61.0\%. A métrica Kappa foi de 56.6\%. Este resultado mostra uma melhora considerável em relação a todos os outros classificadores desenvolvidos, conforme pode ser visto na Figura \ref{fig:nb_vs_wnb}. As Figuras \ref{fig:wnb_features_extras_accuracy_graph} e \ref{fig:wnb_features_extras_kappa_graph} mostram, respectivamente, a acurácia e o Kappa em função do tamanho da base de dados para este classificador.


\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{wnb_features_extras_accuracy_graph.png}
	\caption{Acurácia em função da quantidade de postagens na base de dados (treinamento + validação) para a Weighted NB com features extras}
	\label{fig:wnb_features_extras_accuracy_graph}
\end{figure}


\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{wnb_features_extras_kappa_graph.png}
	\caption{Kappa em função da quantidade de postagens na base de dados (treinamento + validação) para a Weighted NB com features extras}
	\label{fig:wnb_features_extras_kappa_graph}
\end{figure}

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{nb_vs_wnb.png}
	\caption{Comparação dos quatro classificadores propostos, mostrando o Kappa de cada um como uma função do tamanho da base de dados.}
	\label{fig:nb_vs_wnb}
\end{figure}


Analisou-se a matriz de confusão para este classificador, rodando novamente o programa. Para este exemplo teve-se:

$acuracia=0.656085$

$acuracia\_esperada=0.108060$

$Kappa=0.614419$

Uma observação interessante é que com este valor de Kappa, este classificador em específico poderia ser considerado \emph{`Substantial'} pela interpretação do Kappa citada na Seção \ref{sec:kappa}.

A Tabela \ref{tab:weighted_nb_com_features_extras} apresenta a matriz de confusão gerada. A Figura \ref{fig:weighted_nb_com_features_extras} consiste numa representação gráfica da matriz.


\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c  c  c  c  c  c  c  c  c  c  c }
			\hline
			Beb & Cel & Cie & Edu & Esp & Fil & Hum & Min & Not & Pes & Pol & Pro & Sau & Tur\\
			\hline
			5 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
			0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0\\
			0 & 0 & 5 & 7 & 1 & 1 & 0 & 3 & 0 & 0 & 4 & 1 & 1 & 0\\
			0 & 0 & 1 & 0 & 7 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
			0 & 0 & 0 & 1 & 0 & 7 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0\\
			0 & 0 & 0 & 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
			2 & 1 & 0 & 0 & 0 & 0 & 0 & 14 & 2 & 0 & 5 & 0 & 1 & 0\\
			0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0\\
			2 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 24 & 1 & 2 & 0 & 2\\
			1 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 30 & 0 & 1 & 1\\
			0 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 1 & 4 & 0 & 0\\
			0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 2 & 0 & 6 & 0\\
			0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 5\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Matriz de confusao para a Weighted NB com features extras}
	\label{tab:weighted_nb_com_features_extras}
\end{table}

\begin{figure}[ht!]
	\centering	\includegraphics[width=0.9\textwidth]{weighted_nb_com_features_extras.png}
	\caption{Heatmap da matriz de confusão da Tabela \ref{tab:weighted_nb_com_features_extras}}
	\label{fig:weighted_nb_com_features_extras}
\end{figure}

Como pode ser visto na Figura \ref{fig:weighted_nb_com_features_extras} o resultado obtido melhorou consideravelmente. Agora ao Heatmap possui uma diagonal principal com uma tonalidade forte de amarelo e algumas outras células com alguns erros. A confusão entre Minorias e Política ainda acontece, porém numa intensidade bem menor que anteriormente. Além disso observa-se também uma confusão entre as categorias Ciência e Educação (provavelmente pelo fato de ambas falarem sobre universidades).

Outras estatísticas analisadas são as precisões, as abrangências e os f1scores para cada uma das classes, conforme relacionado na Tabela \ref{tab:weighted_nb_com_features_extras_prec_rec}. Observa-se uma melhora considerável. Os f1score micro e macro estão em torno de 65\% agora.

\begin{table}[tph]
	\begin{center}
		\begin{tabular}{ c  c  c  c }
			\hline
			Classe & Precisao & Abrangencia & F1score \\
			\hline
			Bebes & 0.555556 & 0.500000 & 0.526316 \\
			Celebridade & 1.000000 & 0.428571 & 0.600000 \\
			Ciencia & 0.666667 & 0.428571 & 0.521739 \\
			Educacao & 0.304348 & 0.636364 & 0.411765 \\
			Esporte & 0.777778 & 0.875000 & 0.823529 \\
			Filmes & 0.700000 & 0.636364 & 0.666667 \\
			Humor & 1.000000 & 1.000000 & 1.000000 \\
			Minorias & 0.560000 & 0.736842 & 0.636364 \\
			Noticias & 0.500000 & 0.200000 & 0.285714 \\
			Pessoal & 0.727273 & 0.923077 & 0.813559 \\
			Politica & 0.857143 & 0.666667 & 0.750000 \\
			Propaganda & 0.444444 & 0.444444 & 0.444444 \\
			Saude & 0.545455 & 0.600000 & 0.571429 \\
			Turismo & 0.833333 & 0.555556 & 0.666667 \\
			Media Micro & 0.656085 & 0.656085 & 0.656085 \\
			Media Macro & 0.676571 & 0.616533 & 0.645158 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Precisão e abrangencia para Weighted NB com features extras}
	\label{tab:weighted_nb_com_features_extras_prec_rec}
\end{table}

\section{Utilização dos links}

% TODO: Números de utilização dos links!

\section{Fusão de classes pequenas}

% TODO: Números da fusão de classes pequenas!

\section{Extensão final desenvolvida}

\section{Teste de usabilidade}
% Usamos as heuristicas de Nielsen

\section{Análise do classificador de artigos}
 
 % TODO: Números do classificador de artigos